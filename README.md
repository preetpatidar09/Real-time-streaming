# Real-Time CDC Pipeline â€“ MySQL â†’ Kafka â†’ Spark Structured Streaming â†’ Cassandra

## ğŸ“Œ Overview
This project implements a **real-time Change Data Capture (CDC)** pipeline without Debezium or Kafka Connect, using a **timestamp-based CDC** approach.  
It streams only changed rows from **MySQL** into **Kafka**, processes them in **Apache Spark Structured Streaming**, and writes the results into **Cassandra** for real-time analytics.

## ğŸš€ Architecture
**Flow:**
MySQL (with last_updated timestamp)
â†“ (CDC fetch of new/updated rows)
Kafka Producer (Python)
â†“
Apache Kafka
â†“
Spark Structured Streaming (Databricks)
â†“
Cassandra (Astra DB or on-prem)


**Key Features**
- Real-time ingestion without Debezium/Kafka Connect
- Timestamp-based incremental fetch (no full table scan)
- Sub-minute end-to-end latency
- Fault-tolerant & scalable processing
- Ready for operational dashboards & alerts

---

## ğŸ› ï¸ Tech Stack
- **MySQL** â€“ Source database (with `last_updated` timestamp)
- **Apache Kafka** â€“ Messaging backbone
- **Python** â€“ Kafka producer for CDC
- **Apache Spark Structured Streaming (Databricks)** â€“ Real-time processing
- **Cassandra / Astra DB** â€“ Analytics storage

---

## ğŸ“Š Use Cases
- **Business Metrics Dashboard** â€“ Always up-to-date KPIs like orders, revenue, and customer activity
- **Operational Alerts** â€“ Trigger notifications when anomalies are detected in the data stream

---

## ğŸ“¸ Architecture Diagram
![Architecture](architecture.png)
