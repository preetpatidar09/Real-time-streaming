Real Time Streaming
CDC Pipeline â€“ MySQL â†’ Kafka â†’ Spark â†’ Cassandra
ğŸ“Œ Overview
This project demonstrates a real-time Change Data Capture (CDC) pipeline that streams changes from MySQL into Apache Kafka, processes them with Apache Spark Structured Streaming, and stores them in Cassandra for real-time analytics.

With sub-minute end-to-end latency, this pipeline enables up-to-date operational dashboards and business metrics.

ğŸš€ Architecture
Flow:

MySQL â€“ Source database with CDC enabled (e.g., Debezium or Kafka Connect MySQL Source Connector).

Kafka â€“ Streams change events from MySQL.

Spark Structured Streaming â€“ Consumes from Kafka, applies transformations, and handles schema evolution.

Cassandra â€“ Stores processed data for real-time queries.


MySQL  â†’  Kafka  â†’  Spark Structured Streaming  â†’  Cassandra
âœ¨ Key Features
Real-time Change Data Capture (CDC) from MySQL.

Sub-minute end-to-end latency from source to analytics store.

Scalable & fault-tolerant processing with Apache Kafka and Spark.

Schema evolution support via Confluent Schema Registry.

Seamless Cassandra integration for structured, queryable data.

Operational dashboards & analytics-ready data.

ğŸ› ï¸ Tech Stack
MySQL â€“ Source database

Apache Kafka â€“ Messaging backbone

Apache Spark Structured Streaming â€“ Real-time processing

Cassandra â€“ Analytics and query storage

Confluent Schema Registry â€“ Schema evolution and management

ğŸ“Š Use Case
Business Metrics Dashboard â€“ Always up-to-date order counts, revenue, and customer activity.

Operational Alerts â€“ Trigger notifications when anomalies are detected in the data stream.
